# Vietnamese Tax Law GraphRAG System

### Multi-Hop Legal Reasoning over Personal & Corporate Income Tax Documents

---

## üìå Overview

This project builds an end-to-end **GraphRAG pipeline** over Vietnamese tax law documents related to:

* **Personal Income Tax (Thu·∫ø Thu Nh·∫≠p C√° Nh√¢n ‚Äì TNCN)**
* **Corporate Income Tax (Thu·∫ø Thu Nh·∫≠p Doanh Nghi·ªáp ‚Äì TNDN)**

The system:

1. Crawls official legal documents from the **National Legal Document Database of Vietnam**
2. Converts raw Word/PDF files into LLM-ready Markdown
3. Builds a **Knowledge Graph‚Äìenhanced RAG pipeline using LightRAG**
4. Evaluates Traditional RAG vs GraphRAG using a structured benchmarking framework

The goal is to enable **multi-hop regulatory reasoning**, improve groundedness, and reduce hallucination in complex cross-document tax queries.

---

# üèó Project Architecture

The project consists of **4 main stages**:

---

## 1Ô∏è‚É£ Data Collection (Web Scraping)

Script: `vbpl_scraper.py`

* Scrapes official Vietnamese tax law documents
* Source: *National Legal Document Database of Vietnam vbpl.vn*
* Collects ~200 legal documents related to PIT & CIT

After running:

```
output/
 ‚îú‚îÄ‚îÄ thue_thu_nhap_ca_nhan/
 ‚îú‚îÄ‚îÄ thue_thu_nhap_doanh_nghiep/
 ‚îî‚îÄ‚îÄ logs/
```

---

## 2Ô∏è‚É£ Raw Data Organization

Script: `organize_files.py`

* Extracts all Word and PDF files from `output/`
* Stores them in structured raw format

```
raw_data/
 ‚îú‚îÄ‚îÄ pdfs_docs/
 ‚îî‚îÄ‚îÄ word_docs/
```

---

## 3Ô∏è‚É£ Document Conversion (LLM-Ready Markdown)

Script: `markitdown_convert.py`

* Converts all Word & PDF files into Markdown
* Saves Markdown files to:

```
raw_data/markdown_docs/
```

‚ö†Ô∏è Only Markdown files are used in the RAG pipeline.
Original Word/PDF files are preserved but not processed by LightRAG.

---

## 4Ô∏è‚É£ GraphRAG Pipeline (LightRAG)

Directory: `hybrid_workspace/`

### Structure:

```
hybrid_workspace/
 ‚îú‚îÄ‚îÄ markdown_docs/       # LLM-ready legal documents
 ‚îú‚îÄ‚îÄ rag_storage/         # Vector DB + Knowledge Graph storage
 ‚îú‚îÄ‚îÄ logs/
 ‚îú‚îÄ‚îÄ knowledge_graph.html # Graph visualization
 ‚îú‚îÄ‚îÄ .env                 # API keys
 ‚îî‚îÄ‚îÄ scripts/
```

---

# üß† LightRAG Pipeline Components

Located in: `hybrid_workspace/scripts/`

### Core Scripts

* `init_rag.py` ‚Äî Initialize LightRAG with:

  * GPT-4.1-mini (OpenAI API)
  * Local embeddings (SentenceTransformers multilingual-e5-base)
* `index_markdown_docs.py` ‚Äî Chunking, embedding, entity‚Äìrelation extraction
* `query_cli.py` ‚Äî Query in different modes:

  * `naive` (Traditional RAG)
  * `local`
  * `global`
  * `hybrid`
* `debug_retrieval_data.py` ‚Äî Inspect retrieved chunks/entities/relations
* `clear_storage.py` ‚Äî Reset vector DB & graph

---

# üî¨ Evaluation Framework

A structured benchmark was implemented to compare:

> Traditional RAG (vector search) vs GraphRAG (entity‚Äìrelation + vector hybrid)

---

## üìä Dataset

* 120 labeled queries:

  * 60 real-use tax queries
  * 60 stress-test multi-hop queries

Categories:

* Multi-hop conditional reasoning
* Cross-document aggregation
* Concept comparison
* Legal source tracing

---

## ü§ñ LLM-as-a-Judge Rubric (1.0‚Äì10.0 Interval Scale)

Each answer is scored on:

* **Correctness**
* **Completeness**
* **Groundedness**
* **Hallucination**

Evaluation scripts:

* `eval_questions_tax.py`
* `eval_run_modes.py`
* `eval_judge_llm.py`
* `eval_analyze_plot.py`

Generated outputs:

* Histograms
* Box plots
* Radar charts
* Correlation matrices
* Effect size comparisons
* Mean & median per retrieval mode

---


# üõ† Tech Stack

**Core AI Stack**

* Python
* LightRAG (GraphRAG framework)
* GPT-4.1-mini (OpenAI API)
* SentenceTransformers (intfloat/multilingual-e5-base)
* Knowledge Graph construction
* NanoVectorDB (vector similarity search)

**Data & Evaluation**

* AsyncIO
* JSONL pipelines
* Pandas
* NumPy
* Matplotlib
* Seaborn
* LLM-as-a-Judge evaluation

---

# üöÄ How to Run

## 1Ô∏è‚É£ Scrape data

```bash
python vbpl_scraper.py
```

## 2Ô∏è‚É£ Organize files

```bash
python organize_files.py
```

## 3Ô∏è‚É£ Convert to Markdown

```bash
python markitdown_convert.py
```

## 4Ô∏è‚É£ Initialize GraphRAG

```bash
cd hybrid_workspace
python scripts/init_rag.py
```

## 5Ô∏è‚É£ Index documents

```bash
python scripts/index_markdown_docs.py
```

## 6Ô∏è‚É£ Query system

```bash
python scripts/query_cli.py
```

## 7Ô∏è‚É£ Run evaluation

```bash
python scripts/eval_run_modes.py
python scripts/eval_judge_llm.py
python scripts/eval_analyze_plot.py
```

---

# üìä Knowledge Graph Visualization

After indexing, an interactive graph is generated:

```
hybrid_workspace/knowledge_graph.html
```

This visualizes:

* Entities
* Relationships
* Multi-hop connections between tax regulations

---

# üìå Project Goals

* Build a production-ready GraphRAG system for legal intelligence
* Quantitatively compare RAG vs GraphRAG
* Improve groundedness and reduce hallucination in regulatory AI systems
* Create reproducible evaluation framework for legal-domain LLM systems

---

# üìé Future Improvements

* Add citation highlighting
* Implement retrieval confidence scoring
* Extend to other regulatory domains (VAT, investment law)
* Deploy as web-based tax assistant
